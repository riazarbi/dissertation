@article{Probability2018,
author = {Probability, The and Overfitting, Backtest},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Probability, Overfitting - 2018 - Probability of Backtest Overfitting(2).pdf:pdf},
pages = {1--9},
title = {{Probability of Backtest Overfitting}},
volume = {0},
year = {2018}
}
@misc{Munafo2017,
abstract = {Improving the reliability and efficiency of scientific research will increase the credibility of the published scientific literature and accelerate discovery. Here we argue for the adoption of measures to optimize key elements of the scientific process: methods, reporting and dissemination, reproducibility, evaluation and incentives. There is some evidence from both simulations and empirical studies supporting the likely effectiveness of these measures, but their broad adoption by researchers, institutions, funders and journals will require iterative evaluation and improvement. We discuss the goals of these measures, and how they can be implemented, in the hope that this will facilitate action toward improving the transparency, reproducibility and efficiency of scientific research.},
author = {Munaf{\`{o}}, Marcus R and Nosek, Brian A and Bishop, Dorothy V.M. and Button, Katherine S and Chambers, Christopher D and {Percie Du Sert}, Nathalie and Simonsohn, Uri and Wagenmakers, Eric Jan and Ware, Jennifer J and Ioannidis, John P.A.},
booktitle = {Nature Human Behaviour},
doi = {10.1038/s41562-016-0021},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munaf{\`{o}} et al. - 2017 - A manifesto for reproducible science.pdf:pdf},
isbn = {4156201600},
issn = {23973374},
number = {1},
title = {{A manifesto for reproducible science}},
url = {https://www.nature.com/articles/s41562-016-0021.pdf},
volume = {1},
year = {2017}
}
@article{Kraska2017,
abstract = {Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70{\%} in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.},
archivePrefix = {arXiv},
arxivId = {1712.01208},
author = {Kraska, Tim and Beutel, Alex and Chi, Ed H. and Dean, Jeffrey and Polyzotis, Neoklis},
eprint = {1712.01208},
title = {{The Case for Learned Index Structures}},
url = {http://arxiv.org/abs/1712.01208},
year = {2017}
}
@article{Dedeo2017,
author = {Dedeo, Simon},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dedeo - 2017 - Bayesian Reasoning for Intelligent People.pdf:pdf},
title = {{Bayesian Reasoning for Intelligent People}},
year = {2017}
}
@misc{Bessembinder2017,
author = {Bessembinder, Hendrik},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bessembinder - 2017 - Do Stocks Outperform Treasury Bills(2).pdf:pdf},
keywords = {Long horizon returns,return skewness,stock market wealth creation},
month = {nov},
title = {{Do Stocks Outperform Treasury Bills?}},
url = {https://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=2900447},
year = {2017}
}
@article{Daniel2017,
abstract = {Preliminary: Please do not quote without permission -Abstract -In the finance literature, a common practice is to create factor-portfolios by sorting on characteristics associated with average returns. The goal of this exercise is to create a set of portfolios that explain the cross-section of average returns. This result obtains if and only if the set of factor-portfolios span the mean-variance efficient portfolio. We argue that this is unlikely to be the case, as factor portfolios constructed in this way fail to incorporate information about the covariance structure of returns. By using a high statistical power methodology to forecast future covariances, we are able to construct a set of portfolios which capture the characteristic premia, but hedge out much of factor risk. We apply our methodology to the Fama and French (2015) five-factors, and construct a portfolio orthogonal to their factor with annualized Sharpe-ratio of 0.84.},
author = {Daniel, Kent and Mota, Lira and Rottke, Simon and Santos, Tano and Lochstoer, Lars and Jagannathan, Ravi and Tetlock, Paul and Weller, Brian},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daniel et al. - 2017 - The Cross-Section of Risk and Return.pdf:pdf},
title = {{The Cross-Section of Risk and Return}},
url = {http://www.kentdaniel.net/papers/unpublished/dmrs.pdf},
year = {2017}
}
@article{Heaton2017,
abstract = {We develop a simple stock selection model to explain why active equity managers tend to underperform a benchmark index. We motivate our model with the empirical observation that the best performing stocks in a broad market index often perform much better than the other stocks in the index. Randomly selecting a subset of securi-ties from the index may dramatically increase the chance of underperforming the index. The relative likelihood of underperformance by investors choosing active management likely is much more important than the loss to those same investors from the higher fees for active management relative to passive index investing. Thus, active management may be even more challenging than previously believed, and the stakes for finding the best active managers may be larger than previously assumed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1510.03550v2},
author = {Heaton, J B and {Polson J H Witte}, N G and {Beck Herman Palenchar}, Bartlit},
eprint = {arXiv:1510.03550v2},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heaton, Polson J H Witte, Beck Herman Palenchar - 2017 - Why Indexing Works(2).pdf:pdf},
keywords = {Active Management,Indexing,Passive Management},
title = {{Why Indexing Works}},
url = {https://arxiv.org/pdf/1510.03550.pdf},
year = {2017}
}
@misc{LopezdePrado2017,
author = {{Lopez de Prado}, Marcos},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lopez de Prado - 2017 - The 7 Reasons Most Machine Learning Funds Fail (Presentation Slides).pdf:pdf},
keywords = {Machine learning,backtest overfitting,investment strategies,quantamental investing},
month = {sep},
title = {{The 7 Reasons Most Machine Learning Funds Fail (Presentation Slides)}},
url = {https://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=3031282},
year = {2017}
}
@article{Hou2017,
abstract = {The anomalies literature is infested with widespread p-hacking. We replicate the entire anomalies literature in finance and accounting by compiling a largest-to-date data library that contains 447 anomaly variables. With microcaps alleviated via New York Stock Exchange breakpoints and value-weighted returns, 286 anomalies (64{\%}) including 95 out of 102 liquidity variables (93{\%}) are insignificant at the conventional 5{\%} level. Imposing the cutoff t-value of three raises the number of insignificance to 380 (85{\%}). Even for the 161 significant anomalies, their magnitudes are often much lower than originally reported. Out of the 161, the q-factor model leaves 115 alphas insignificant (150 with t {\textless} 3). In all, capital markets are more efficient than previously recognized.},
author = {Hou, Kewei and Xue, Chen and Zhang, Lu},
doi = {10.2139/ssrn.2190976},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hou, Xue, Zhang - 2017 - Replicating anomalies.pdf:pdf},
issn = {1556-5068},
journal = {NBER Working Papers},
keywords = {Asset Pricing,Corporate Finance,Economic Fluctua},
number = {No. 23394},
title = {{Replicating anomalies}},
url = {https://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=2961979},
year = {2017}
}
@article{Franke2016,
abstract = {The need for new methods to deal with big data is a common theme in most scientific fields, although its definition tends to vary with the context. Statistical ideas are an essential part of this, and as a partial response, a thematic program on statistical inference, learning and models in big data was held in 2015 in Canada, under the general direction of the Canadian Statistical Sciences Institute, with major funding from, and most activities located at, the Fields Institute for Research in Mathematical Sciences. This paper gives an overview of the topics covered, describing challenges and strategies that seem common to many different areas of application and including some examples of applications to make these challenges and strategies more concrete.},
archivePrefix = {arXiv},
arxivId = {1509.02900},
author = {Franke, Beate and Plante, Jean-Fran{\c{c}}ois and Roscher, Ribana and Lee, En-shiun Annie and Smyth, Cathal and Hatefi, Armin and Chen, Fuqi and Gil, Einat and Schwing, Alexander and Selvitella, Alessandro and Hoffman, Michael M. and Grosse, Roger and Hendricks, Dieter and Reid, Nancy},
doi = {10.1111/insr.12176},
eprint = {1509.02900},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Franke et al. - 2016 - Statistical Inference, Learning and Models in Big Data.pdf:pdf},
issn = {03067734},
journal = {International Statistical Review},
keywords = {aggregation,computational complexity,dimension reduction,high-dimensional data,networks,streaming data},
number = {3},
pages = {371--389},
title = {{Statistical Inference, Learning and Models in Big Data}},
url = {http://doi.wiley.com/10.1111/insr.12176},
volume = {84},
year = {2016}
}
@article{Meerkamp2016,
abstract = {We present an architecture for information extraction from text that augments an existing parser with a character-level neural network. The network is trained using a measure of consistency of extracted data with existing databases as a form of noisy supervision. Our architecture combines the ability of constraint-based information extraction systems to easily incorporate domain knowledge and constraints with the ability of deep neural networks to leverage large amounts of data to learn complex features. Boosting the existing parser's precision, the system led to large improvements over a mature and highly tuned constraint-based production information extraction system used at Bloomberg for financial language text.},
archivePrefix = {arXiv},
arxivId = {1612.04118},
author = {Meerkamp, Philipp and Zhou, Zhengyi},
eprint = {1612.04118},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meerkamp, Zhou - Unknown - Information Extraction with Character-level Neural Networks and Free Noisy Supervision.pdf:pdf},
title = {{Information Extraction with Character-level Neural Networks and Free Noisy Supervision}},
url = {http://arxiv.org/abs/1612.04118},
year = {2016}
}
@article{Valkenburgh2016,
abstract = {This report offers a non-technical but thorough explanation of " blockchain technology " with a focus on the key variables within consensus mechanism design that differentiate so-called permissioned or closed and permissionless or open blockchains. We describe decentralized computing generally and draw parallels between open blockchain networks, e.g. Bitcoin, Ethereum, and Zcash, and the early Internet. For certain use cases, we explain why open networks may be more worthy of user trust and more capable of ensuring user privacy and security. Our highlighted use cases are electronic cash, digital identity, and the Internet of Things. Electronic cash promises efficient microtransactions, and enhanced financial inclusion; robust digital identity may solve many of our online security woes and streamline commerce and interaction online; and blockchain-driven Internet of Things systems may spur greater security, competition, and an end to walled gardens of non-interoperability for connected devices. We argue that the full benefits of these potential use cases can only be realized by utilizing open blockchain networks.},
author = {Valkenburgh, Peter Van},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Valkenburgh - 2016 - Open Matters Why Permissionless Blockchains are Essential to the Future of the Internet.pdf:pdf},
title = {{Open Matters Why Permissionless Blockchains are Essential to the Future of the Internet}},
year = {2016}
}
@article{Brodeur2016,
author = {Brodeur, Abel and L{\'{e}}, Mathias and Sangnier, Marc and Zylberberg, Yanos},
doi = {10.1257/app.20150044},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brodeur et al. - 2016 - Star Wars The Empirics Strike Back.pdf:pdf},
issn = {1945-7782},
journal = {American Economic Journal: Applied Economics},
month = {jan},
number = {1},
pages = {1--32},
title = {{Star Wars: The Empirics Strike Back}},
url = {http://pubs.aeaweb.org/doi/10.1257/app.20150044},
volume = {8},
year = {2016}
}
@article{Hou2016,
abstract = {This paper conducts a gigantic replication study of asset pricing anomalies by compiling an extensive data library with 437 variables. After microcaps are controlled for, 276 anomalies with NYSE breakpoints and value-weighted returns, as well as 221 with all-but-micro breakpoints and equal-weighted returns, including a vast majority of liquidity variables, are insignificant at the 5{\%} level. When explaining the remaining hundreds of significant anomalies, the q-factor model and a closely related five-factor model are the two best performing models among a long list of models. Investment and profitability are the dominating driving forces in the broad cross section of average stock returns.},
author = {Hou, Kewei and Xue, Chen and Zhang, Lu and Cooper, Ilan and Giovinazzo, Raife and Kozak, Serhiy and Murray, Scott and Ng, David and Opp, Christian and Shanken, Jay and Simin, Timothy and Wang, Zhenyu and Berk, Jonathan and Brennan, Michael and Chapman, David and Keim, Don and Kolari, Jim and Li, Dongxu and Poterba, Jim and Sensoy, Berk and Stambaugh, Rob and Stulz, Ren{\'{e}} and Titman, Sheridan and Weisbach, Michael and Werner, Ingrid and Yao, Tong and Yaron, Amir},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hou et al. - 2016 - A Comparison of New Factor Models.pdf:pdf},
title = {{A Comparison of New Factor Models}},
url = {http://theinvestmentcapm.com/Comparison2016November.pdf},
year = {2016}
}
@article{Harvey2015,
abstract = {When evaluating a trading strategy, it is routine to discount the Sharpe ratio from a historical backtest. The reason is simple: there is inevitable data min- ing by both the researcher and by other researchers in the past. Our paper provides a statistical framework that systematically accounts for these multiple tests. We propose a method to determine the appropriate haircut for any given reported Sharpe ratio. We also provide a profit hurdle that any strategy needs to achieve in order to be deemed “significant”.},
author = {Harvey, Campbell R and Liu, Yan},
doi = {10.2139/ssrn.2345489},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harvey, Liu - 2015 - Backtesting.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {Backtest,Data mining,Data snooping,Haircut,Minimum profit hurdle.,Multiple tests,Out-of-sample tests,Overfitting,Sharpe ratio,Trad- ing strategies,VaR,Value at Risk},
title = {{Backtesting}},
url = {http://www.ssrn.com/abstract=2345489},
year = {2015}
}
@article{Hou2015,
abstract = {This paper compares the Hou, Xue, and Zhang (2015) q-factor model and the Fama and French (2015a) five-factor model on both conceptual and empirical grounds. Four concerns cast doubt on the five-factor model: The internal rate of return often correlates negatively with the one-period-ahead expected return; the value factor seems redundant in the data; the expected investment tends to correlate positively with the one-period-ahead expected return; and past investment is a poor proxy for the expected investment. Empirically, the four-factor q-model outperforms the five-factor model, especially in capturing price and earnings momentum and profitability anomalies.},
author = {Hou, Kewei and Xue, Chen and Zhang, Lu and Cooper, Ilan and Giovinazzo, Raife and Kozak, Serhiy and Murray, Scott and Opp, Christian and Shanken, Jay and Simin, Timothy and Wang, Zhenyu and Berk, Jonathan and Brennan, Michael and Chapman, David and Kolari, Jim and Li, Dongxu and Poterba, Jim and Sensoy, Berk and Stulz, Ren{\'{e}} and Titman, Sheridan and Weisbach, Michael and Werner, Ingrid},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hou et al. - 2015 - A Comparison of New Factor Models.pdf:pdf},
title = {{A Comparison of New Factor Models}},
url = {http://fbe.usc.edu/seminars/papers/F{\_}4-22-16{\_}ZHANG.pdf},
year = {2015}
}
@article{Wilcox2015,
abstract = {We discuss the finding that cross-sectional characteristic based models have yielded portfolios with higher excess monthly returns but lower risk than their arbitrage pricing theory counterparts in an analysis of equity returns of stocks listed on the JSE. Under the assumption of general no-arbitrage conditions, we argue that evidence in favour of characteristic based pricing implies that information is more likely assimilated by means of nonlinear pricing kernels for the markets considered.},
archivePrefix = {arXiv},
arxivId = {1310.4067},
author = {Wilcox, Diane L. and Gebbie, Tim J.},
doi = {10.1080/10293523.2014.994437},
eprint = {1310.4067},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilcox, Gebbie - 2015 - On pricing kernels, information and risk.pdf:pdf;:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilcox, Gebbie - 2015 - On pricing kernels, information and risk(2).pdf:pdf},
issn = {20770227},
journal = {Investment Analysts Journal},
keywords = {Arbitrage pricing theory,Characteristic-based models,Linear pricing kernel,Non-linear pricing kernel,Size effect,Value effect},
number = {1},
pages = {1--19},
title = {{On pricing kernels, information and risk}},
volume = {44},
year = {2015}
}
@article{Langkvist2014,
abstract = {This paper gives a review of the recent developments in deep learning and unsupervised feature learning for time-series problems. While these techniques have shown promise for modeling static data, such as computer vision, applying them to time-series data is gaining increasing attention. This paper overviews the particular challenges present in time-series data and provides a review of the works that have either applied time-series data to unsupervised feature learning algorithms or alternatively have contributed to modifications of feature learning algorithms to take into account the challenges present in time-series data. {\textcopyright} 2014 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {1602.07261},
author = {L{\"{a}}ngkvist, Martin and Karlsson, Lars and Loutfi, Amy},
doi = {10.1016/j.patrec.2014.01.008},
eprint = {1602.07261},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\"{a}}ngkvist, Karlsson, Loutfi - 2014 - A review of unsupervised feature learning and deep learning for time-series modeling.pdf:pdf},
isbn = {0167-8655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Deep learning,Time-series,Unsupervised feature learning},
number = {1},
pages = {11--24},
pmid = {23064159},
title = {{A review of unsupervised feature learning and deep learning for time-series modeling}},
volume = {42},
year = {2014}
}
@article{,
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2014 - Bloomberg API.pdf:pdf},
title = {{Bloomberg API}},
year = {2014}
}
@article{Harvey2014,
abstract = {We propose a new regression method to select amongst a large group of candidate factors - many of which might be the result of data mining - that purport to explain the cross-section of expected returns. The method is robust to general distributional characteristics of both factor and asset returns. We allow for the possibility of time-series as well as cross-sectional dependence. The technique accommodates a wide range of test statistics such as t-ratios. While our main application focuses on asset pricing, the method can be applied in any situation where regression analysis is used in the presence of multiple testing. This includes, for example, the evaluation of investment manager performance as well as time-series prediction of asset returns.},
author = {Harvey, Campbell R. and Liu, Yan},
doi = {10.2139/ssrn.2528780},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harvey, Liu - 2014 - Lucky Factors.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {bootstrap,data mining,factors,fama-macbeth,grs,ization,multiple testing,orthogonal-,predictive regressions,variable selection},
title = {{Lucky Factors}},
url = {http://papers.ssrn.com/abstract=2528780{\%}5Cnhttp://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=2528780},
year = {2014}
}
@article{Harvey2014a,
abstract = {We provide some new tools to evaluate trading strate- gies. When it is known that many strategies and combinations of strategies have been tried, we need to adjust our evaluation method for these multiple tests. Sharpe ratios and other statistics will be overstated. Our methods are simple to implement and allow for the real-time evaluation of candidate trading strategies.},
author = {Harvey, Campbell R and Liu, Yan},
doi = {10.3905/jpm.2014.40.5.108},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harvey, Liu - 2014 - Evaluating Trading Strategies.pdf:pdf},
issn = {0095-4918},
journal = {The Journal of Portfolio Management},
number = {5},
pages = {108--118},
title = {{Evaluating Trading Strategies}},
url = {http://www.iijournals.com/doi/abs/10.3905/jpm.2014.40.5.108},
volume = {40},
year = {2014}
}
@article{Gebbie2014,
author = {Gebbie, Tim},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gebbie - 2014 - Evidence of characteristic cross-sectional pricing on the JSE.pdf:pdf},
title = {{Evidence of characteristic cross-sectional pricing on the JSE}},
year = {2014}
}
@article{Bailey2014,
abstract = {We prove that high simulated performance is easily achievable after backtesting a relatively small number of alternative strategy configurations, a practice we denote “backtest overfitting”. The higher the number of configurations tried, the greater is the probability that the backtest is overfit. Because most financial analysts and academics rarely report the number of configurations tried for a given backtest, investors cannot evaluate the degree of overfitting in most investment proposals. The implication is that investors can be easily misled into allocating capital to strategies that appear to be mathematically sound and empirically supported by an outstanding backtest. Under memory effects, backtest overfitting leads to negative expected returns out-of-sample, rather than zero performance. This may be one of several reasons why so many quantitative funds appear to fail.},
author = {Bailey, David H. and Borwein, Jonathan M. and {L{\'{o}}pez de Prado}, Marcos and Zhu, Qiji Jim},
doi = {10.2139/ssrn.2308659},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bailey et al. - 2014 - Pseudo-Mathematics and Financial Charlatanism The Effects of Backtest Overfitting on Out-of-Sample Performance.pdf:pdf;:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bailey et al. - 2014 - Pseudo-Mathematics and Financial Charlatanism The Effects of Backtest Overfitting on Out-of-Sample Performance(2).pdf:pdf;:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bailey et al. - 2014 - Pseudo-Mathematics and Financial Charlatanism The Effects of Backtest Overfitting on Out-of-Sample Performance(3).pdf:pdf},
issn = {1556-5068},
journal = {Notices of the AMS},
keywords = {Sharpe ratio,backtest,historical simulation,investment strategy,minimum backtest length,optimization,performance degradation,probability of backtest over-fitting},
number = {5},
pages = {458--471},
title = {{Pseudo-Mathematics and Financial Charlatanism: The Effects of Backtest Overfitting on Out-of-Sample Performance}},
url = {http://papers.ssrn.com/abstract=2308659},
volume = {61},
year = {2014}
}
@article{LopezdePrado2013,
abstract = {Most firms and portfolio managers rely on backtests (or historical simulations of performance) to select investment strategies and allocate them capital. Standard statistical techniques designed to prevent regression over-fitting, such as hold-out, tend to be unreliable and inaccurate in the context of investment backtests. We propose a framework that estimates the probability of backtest over-fitting (PBO) specifically in the context of investment simulations, through a numerical method that we call combinatorially symmetric cross-validation (CSCV). We show that CSCV produces accurate estimates of the probability that a particular backtest is over-fit.},
author = {{Lopez de Prado}, Marcos},
doi = {10.2139/ssrn.2308682},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Probability, Overfitting - 2018 - Probability of Backtest Overfitting(2).pdf:pdf;:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lopez de Prado - 2013 - The Probability of Back-Test Over-Fitting.pdf:pdf},
isbn = {047125391X},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
title = {{The Probability of Back-Test Over-Fitting}},
url = {http://www.ssrn.com/abstract=2308682},
year = {2013}
}
@article{Sylvain2013,
abstract = {I reproduce the results of Fama and MacBeth (1973) and extend this paper in several ways. First, I use twenty-five test portfolios constructed using a double-sort on betas and standard deviations of the residuals of the underlying securities (while still maintaining the same timing assumptions and method of Fama and MacBeth; 1973). I find that the coefficient on the average standard deviation of the residuals becomes significant in the cross-sectional regressions, even for the 1929-1968 time period. This goes against some of the results in Fama and MacBeth (1973) and hints that these results may not have been robust. In particular, I alternate between using an equal-weighted and value-weighted NYSE portfolio as proxy for the market portfolio. I also alternate the construction of the test portfolio estimates between equal-weighting and value-weighting of the underlying securities estimates. I find that the Fama-MacBeth (1973) results are unaffected by these variations if the test portfolios are constructed using a single sort on betas as done in Fama-MacBeth (1973). But with test portfolios built with a dual-sort much of the Fama-MacBeth (1973) results are undone. ¦ I am grateful to Aaron Foss for providing me with helpful comments, suggestions, and feedback.},
author = {Sylvain, Serginio},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sylvain - 2013 - Fama-MacBeth 1973 Replication and Extension.pdf:pdf},
title = {{Fama-MacBeth 1973: Replication and Extension}},
url = {http://home.uchicago.edu/{~}serginio/research/FamaPaper{\_}fm73replication{\_}extension.pdf},
year = {2013}
}
@inproceedings{Stodden2013,
abstract = {Science is built upon foundations of theory and experiment validated and improved through open, trans-parent communication. With the increasingly central role of computation in scientific discovery this means communicating all details of the computations needed for others to replicate the experiment, i.e. making avail-able to others the associated data and code. The " reproducible research " movement recognizes that traditional scientific research and publication practices now fall short of this ideal, and encourages all those involved in the production of computational science – scientists who use computational methods and the institutions that employ them, journals and dissemination mechanisms, and funding agencies – to facilitate and practice really reproducible research. This report summarizes discussions that took place during the ICERM Workshop on Reproducibility in Computational and Experimental Mathematics, held December 10-14, 2012. The main recommendations that emerged from the workshop discussions are: 1. It is important to promote a culture change that will integrate computational reproducibility into the research process. 2. Journals, funding agencies, and employers should support this culture change. 3. Reproducible research practices and the use of appropriate tools should be taught as standard operat-ing procedure in relation to computational aspects of research. The workshop discussions included presentations of a number of the diverse and rapidly growing set of soft-ware tools available to aid in this effort. We call for a broad implementation of these three recommendations across the computational sciences.},
author = {Stodden, V and Bailey, D H and Borwein, J and Leveque, R J and Rider, W and Stein, W},
booktitle = {ICERM workshop},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stodden et al. - Unknown - Setting the Default to Reproducible Reproducibility in Computational and Experimental Mathematics.pdf:pdf},
pages = {19},
title = {{Setting the Default to Reproducible Reproducibility in Computational and Experimental Mathematics}},
url = {http://www.davidhbailey.com/dhbpapers/icerm-report.pdf},
year = {2013}
}
@article{Harvey2013,
abstract = {Hundreds of papers and factors attempt to explain the cross-section of expected returns. Given this extensive data mining, it does not make sense to use the usual criteria for establishing significance. Which hurdle should be used for current research? Our paper introduces a new multiple testing framework and provides historical cutoffs from the first empirical tests in 1967 to today. A new factor needs to clear a much higher hurdle, with a t-statistic greater than 3.0. We argue that most claimed research findings in financial economics are likely false.Received October 22, 2014; accepted June 15, 2015 by Editor Andrew Karolyi.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Harvey, Campbell R. and Liu, Yan and Zhu, Heqing},
doi = {10.1093/rfs/hhv059},
eprint = {9809069v1},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harvey, Liu, Zhu - 2013 - ...and the Cross-Section of Expected Returns.pdf:pdf},
isbn = {9780874216561},
issn = {14657368},
journal = {Review of Financial Studies},
keywords = {3-factor model,beta,bonferroni,hml,idiosyncratic volatility,liquidity,momentum,multiple tests,risk factors,skewness,smb,volatility},
number = {1},
pages = {5--68},
pmid = {15003161},
primaryClass = {arXiv:gr-qc},
title = {{...and the Cross-Section of Expected Returns}},
volume = {29},
year = {2013}
}
@article{Jarrow2012,
abstract = {We improve upon the power of the statistical arbitrage test in Hogan, Jarrow, Teo, and Warachka (2004). Our methodology also allows for the evaluation of return anomalies under weaker assumptions. We then compare strategies based on their convergence rates to arbitrage and identify strategies whose probability of a loss declines to zero most rapidly. These strategies are preferred by investors with finite horizons or limited capital. After controlling for market frictions and examining convergence rates to arbitrage, we find that momentum and value strategies offer the most desirable trading opportunities. {\textcopyright} 2011 Elsevier B.V.},
author = {Jarrow, Robert and Teo, Melvyn and Tse, Yiu Kuen and Warachka, Mitch},
doi = {10.1016/j.finmar.2011.08.003},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jarrow et al. - 2012 - An improved test for statistical arbitrage.pdf:pdf},
issn = {13864181},
journal = {Journal of Financial Markets},
keywords = {Bootstrap,Momentum strategy,Statistical arbitrage,Value strategy},
number = {1},
pages = {47--80},
publisher = {Elsevier},
title = {{An improved test for statistical arbitrage}},
url = {http://dx.doi.org/10.1016/j.finmar.2011.08.003},
volume = {15},
year = {2012}
}
@article{Fama2012,
abstract = {a b s t r a c t In the four regions (North America, Europe, Japan, and Asia Pacific) we examine, there are value premiums in average stock returns that, except for Japan, decrease with size. Except for Japan, there is return momentum everywhere, and spreads in average momentum returns also decrease from smaller to bigger stocks. We test whether empirical asset pricing models capture the value and momentum patterns in interna-tional average returns and whether asset pricing seems to be integrated across the four regions. Integrated pricing across regions does not get strong support in our tests. For three regions (North America, Europe, and Japan), local models that use local explanatory returns provide passable descriptions of local average returns for portfolios formed on size and value versus growth. Even local models are less successful in tests on portfolios formed on size and momentum.},
author = {Fama, Eugene F and French, Kenneth R},
doi = {10.1016/j.jfineco.2012.05.011},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fama, French - 2012 - Size, value, and momentum in international stock returns.pdf:pdf},
keywords = {Four-factor model,Momentum,Three-factor model,Value premium},
title = {{Size, value, and momentum in international stock returns}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.409.2911{\&}rep=rep1{\&}type=pdf},
year = {2012}
}
@article{Farmer2009,
abstract = {The use of equilibrium models in economics springs from the desire for parsimonious models of economic phenomena that take human reasoning into account. This approach has been the cornerstone of modern economic theory. We explain why this is so, extolling the virtues of equilibrium theory; then we present a critique and describe why this approach is inherently limited, and why economics needs to move in new directions if it is to continue to make progress. We stress that this shouldn't be a question of dogma, but should be resolved empirically. There are situations where equilibrium models provide useful predictions and there are situations where they can never provide useful predictions. There are also many situations where the jury is still out, i.e., where so far they fail to provide a good description of the world, but where proper extensions might change this. Our goal is to convince the skeptics that equilibrium models can be useful, but also to make traditional economists more aware of the limitations of equilibrium models. We sketch some alternative approaches and discuss why they should play an important role in future research in economics.},
archivePrefix = {arXiv},
arxivId = {0803.2996},
author = {Farmer, J. Doyne and Geanakoplos, John},
doi = {10.1002/cplx.20261},
eprint = {0803.2996},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farmer, Geanakoplos - 2009 - The virtues and vices of equilibrium and the future of financial economics.pdf:pdf},
isbn = {1076-2787},
issn = {10762787},
journal = {Complexity},
keywords = {Agent-based modeling,Arbitrage,Bounded rationality,Disequilibrium,Efficiency,Equilibrium,Market ecology,Power laws,Rational expectations,Zero intelligence},
number = {3},
pages = {11--38},
pmid = {20332},
title = {{The virtues and vices of equilibrium and the future of financial economics}},
volume = {14},
year = {2009}
}
@misc{Fama2009,
author = {Fama, Eugene and French, Kenneth},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fama, French - 2009 - Luck Versus Skill in the Cross Section of Mutual Fund Returns.pdf:pdf},
month = {dec},
title = {{Luck Versus Skill in the Cross Section of Mutual Fund Returns}},
url = {https://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=1356021},
year = {2009}
}
@book{Martin2009,
address = {Boston},
author = {Martin, Robert C},
edition = {First},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin - 2009 - Clean Code A Handbook of Agile Software Craftsmanship.pdf:pdf},
isbn = {9780132350884},
publisher = {Prentice Hall},
title = {{Clean Code: A Handbook of Agile Software Craftsmanship}},
year = {2009}
}
@article{Patton2008,
author = {Patton, Andrew and Timmermann, Allan and Patton, Ndrew},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patton, Timmermann, Patton - 2008 - Portfolio Sorts and Tests of Cross-Sectional Patterns in Expected Returns.pdf:pdf},
title = {{Portfolio Sorts and Tests of Cross-Sectional Patterns in Expected Returns}},
url = {http://public.econ.duke.edu/{~}ap172/Patton{\_}sorts{\_}pres{\_}jun08.pdf},
year = {2008}
}
@article{,
abstract = {Counsel: D B Leburu for the applicant.. . Nthai (with him T Ketshabile) for the accused. Flynote Administration of estates -Deceased estate -Liquidation and distribution account -Distribution -Review -Grounds -Executors misconstruing mandate -Distribution to be made in accordance with consent order -Executors failing to comply with court order -Distribution reviewed and set aside -Court substituting own decision for decision set aside.. 2007 (3) BLR p274 Headnote The applicant made application for the review of the distribution of a deceased estate in accordance with an earlier consent order on the grounds that, in making the distribution, the executors (third and fourth respondents), inter alia, acted contrary to the court order.Held: (1) On the evidence, the executors totally misconstrued their mandate in terms of the court order. In the result, they effected an incorrect division of the estate which had to be reviewed and set aside. (2) In the present case, it was appropriate for the court to substitute its own decision for the decision that had been set aside, rather than send it back to the executors to be decided afresh. That was the case because it would cause unjustifiable prejudice to all the parties if the division were further delayed by sending it back. The court was in as good a position, probably better, than any new appointee, in fulfilling the terms of the court order. Arbi v Commissioner of Prisons and Another [1992] B.L.R. 246, CA at p 255 applied.},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2007 - THIPE AND ANOTHER v THIPE AND OTHERS IN RE THIPE AND ANOTHER v THIPE AND ANOTHER 2007 (3) BLR 273 (H.pdf:pdf},
title = {{THIPE AND ANOTHER v THIPE AND OTHERS; IN RE THIPE AND ANOTHER v THIPE AND ANOTHER 2007 (3) BLR 273 (H}},
year = {2007}
}
@article{Bloomberg2007,
author = {Bloomberg},
doi = {10.1007/b138723},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bloomberg - 2007 - Function Reference.pdf:pdf},
isbn = {3-211-21137-3},
journal = {Security},
number = {October},
title = {{Function Reference}},
year = {2007}
}
@book{Ross2005,
abstract = {EBIB.E72.A0290 check priv{\'{e}}},
author = {Ross, Stephen A},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ross - Unknown - Neoclassical Finance.pdf:pdf},
isbn = {0691121389},
pages = {120 pp.},
pmid = {13671762},
title = {{Neoclassical Finance}},
year = {2005}
}
@article{Ioannidis2005,
author = {Ioannidis, John P. A.},
doi = {10.1371/journal.pmed.0020124},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ioannidis - 2005 - Why Most Published Research Findings Are False.pdf:pdf},
issn = {1549-1676},
journal = {PLoS Medicine},
month = {aug},
number = {8},
pages = {e124},
publisher = {Public Library of Science},
title = {{Why Most Published Research Findings Are False}},
url = {http://dx.plos.org/10.1371/journal.pmed.0020124},
volume = {2},
year = {2005}
}
@misc{Zhang2005,
abstract = {The value anomaly arises naturally in the neoclassical framework with rational ex- pectations. Costly reversibility and countercyclicalprice of risk cause assets in place to be harder to reduce, and hence are riskier than growth options especially in bad times when the price of risk is high. By linking risk and expected returns to economic primitives, such as tastes and technology, my model generates many empirical regularities in the cross-section of returns; it also yields an array of new refutable hypotheses providingfresh directionsforfuture empiricalresearch.},
author = {Zhang, Lu},
booktitle = {Journal of Finance},
doi = {10.1111/j.1540-6261.2005.00725.x},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ZHANG - 2005 - The Value Premium.pdf:pdf},
isbn = {00221082},
issn = {00221082},
month = {feb},
number = {1},
pages = {67--103},
publisher = {Blackwell Publishing, Inc.},
title = {{The value premium}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.2005.00725.x},
volume = {60},
year = {2005}
}
@article{Chriss2005,
abstract = {Modern portfolio theory produces an optimal portfolio from estimates of expected returns and a covariance matrix. We present a method for portfolio optimization based on replacing expected returns with ordering information, that is, with information about the order of the expected returns. We give a simple and economically rational definition of optimal portfolios that extends Markowitz' meanvariance optimality condition in a natural way; in particular, our construction allows full use of covariance information. We also provide efficient numerical algorithms. The formulation we develop is very general and is easily extended to a variety of cases, for example, where assets are divided into multiple sectors or there are multiple sorting criteria available.},
author = {Chriss, Neil and Almgren, Robert},
doi = {10.2139/ssrn.720041},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almgren, Chriss - 2005 - Portfolios from Sorts.pdf:pdf},
issn = {1556-5068},
journal = {Available at SSRN 720041},
pages = {1--22},
title = {{Portfolios from sorts}},
url = {https://cims.nyu.edu/{~}almgren/papers/sort.pdf http://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=720041},
year = {2005}
}
@article{Carlson2004,
abstract = {We show that corporate investment decisions can explain the conditional dynamics in expected asset returns. Our approach is similar in spirit to Berk, Green, and Naik (1999), but we introduce to the investment problem operating leverage, reversible real options, fixed adjustment costs, and finite growth opportunities. Asset betas vary over time with historical investment decisions and the current product market demand. Book-to-market effects emerge and relate to operating leverage, while size captures the residual importance of growth options relative to assets in place. We estimate and test the model using simulation methods and reproduce portfolio excess returns comparable to the data. CORPORATE INVESTMENT DECISIONS are often evaluated in a real options context,},
author = {Carlson, Murray and Fisher, Adlai and Giammarino, Ron},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carlson, Fisher, Giammarino - 2004 - Corporate Investment and Asset Price Dynamics Implications for the Cross-section of Returns.pdf:pdf},
journal = {THE JOURNAL OF FINANCE},
number = {6},
title = {{Corporate Investment and Asset Price Dynamics: Implications for the Cross-section of Returns}},
url = {http://faculty.haas.berkeley.edu/garleanu/ReadingGroup{\_}AP{\_}Sp2012/CarlsonFisherGiammarino2004.pdf},
year = {2004}
}
@article{Ross2002,
abstract = {No abstract available.},
author = {Ross, Steven A.},
doi = {10.1111/1468-036X.00181},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ross - 2002 - Neoclassical finance, alternative finance and the closed end fund puzzle.pdf:pdf},
isbn = {1468-036X},
issn = {1468036X},
journal = {European Financial Management},
title = {{Neoclassical finance, alternative finance and the closed end fund puzzle}},
year = {2002}
}
@article{Daniel2001,
abstract = {Japanese stock returns are even more closely related to their book-to-market ratios than are their U.S. counterparts, and thus provide a good setting for testing whether the return premia associated with these characteristics arise because the charac- teristics are proxies for covariance with priced factors. Our tests, which replicate the Daniel and Titman {\~{}}1997! tests on a Japanese sample, reject the Fama and French {\~{}}1993! three-factor model, but fail to reject the characteristic model.},
author = {Daniel, Kent and Titman, Sheridan and Wei, K. C.John},
doi = {10.1111/0022-1082.00344},
isbn = {00221082},
issn = {00221082},
journal = {Journal of Finance},
number = {2},
pages = {743--766},
pmid = {222581},
publisher = {WileyAmerican Finance Association},
title = {{Explaining the cross-section of stock returns in Japan: Factors or characteristics?}},
url = {https://www.jstor.org/stable/222581},
volume = {56},
year = {2001}
}
@article{Fielding2000,
author = {Fielding, Roy Thomas},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fielding - 2000 - UNIVERSITY OF CALIFORNIA, IRVINE Architectural Styles and the Design of Network-based Software Architectures.pdf:pdf},
title = {{UNIVERSITY OF CALIFORNIA, IRVINE Architectural Styles and the Design of Network-based Software Architectures}},
year = {2000}
}
@article{Villalonga2000,
abstract = {This paper documents the process followed to match establishment-level data from the Census Bureau's Business Information Tracking Series (BITS) to firm-level data from Standard and Poor's Compustat. The resulting database provides information on the financial characteristics of public U.S. firms and a more objective and detailed breakdown of their activities by industry than that offered by segment-level data. The merged database is therefore an extremely rich source of information that can be used to investigate a variety of topics. The paper also compares the different large-sample databases that have so far been available for academic research within firms, with a particular application to research on corporate diversification. Finally, a brief description of the matching file that is now available at the Center for Economic Studies is also provided.},
author = {Villalonga, Bel{\'{e}}n},
keywords = {Compustat,The Business Information Tracking Series (BITS),diversification,the Longitudinal Enterprise and Establishment Micr},
number = {December},
title = {{Matching BITS to Compustat: Towards richer data for large sample research within firms}},
year = {2000}
}
@misc{Daniel1999,
author = {Daniel, Kent and Wei, K.C. and Titman, Sheridan},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daniel, Wei, Titman - 1999 - Explaining the Cross-Section of Stock Returns in Japan Factors or Characteristics.pdf:pdf},
month = {jul},
title = {{Explaining the Cross-Section of Stock Returns in Japan: Factors or Characteristics?}},
url = {https://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=202433},
year = {1999}
}
@article{Berk1999,
author = {Berk, Jonathan B. and Green, Richard C. and Naik, Vasant},
doi = {10.1111/0022-1082.00161},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berk, Green, Naik - 1999 - Optimal Investment, Growth Options, and Security Returns.pdf:pdf},
issn = {00221082},
journal = {The Journal of Finance},
month = {oct},
number = {5},
pages = {1553--1607},
publisher = {Blackwell Publishers, Inc.},
title = {{Optimal Investment, Growth Options, and Security Returns}},
url = {http://doi.wiley.com/10.1111/0022-1082.00161},
volume = {54},
year = {1999}
}
@article{Daniel1997,
abstract = {Firm sizes and book-to-market ratios are both highly correlated with the average returns of common stocks. Fama and French (1993) argue that the association between these characteristics and returns arise because the characteristics are proxies for nondiversifiable factor risk. In contrast, the evidence in this article indicates that the return premia on small capitalization and high book-to-market stocks does not arise because of the comovements of these stocks with pervasive factors. It is the characteristics rather than the covariance structure of returns that appear to explain the cross-sectional variation in stock returns.},
author = {Daniel, Kent and Titman, Sheridan},
doi = {10.2307/2329554},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daniel, Titman - 1997 - Evidence on the Characteristics of Cross Sectional Variation in Stock Returns.pdf:pdf;:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daniel, Titman - Unknown - ( YLGHQFH RQ WKH {\&} KDUDFWHULVWLFV RI {\&} URVV 6HFWLRQDO 9DULDWLRQ LQ.pdf:pdf},
isbn = {00221082},
issn = {00221082},
journal = {The Journal of Finance},
number = {1},
pages = {1},
pmid = {2329554},
title = {{Evidence on the Characteristics of Cross Sectional Variation in Stock Returns}},
url = {http://www.jstor.org/stable/2329554?origin=crossref},
volume = {52},
year = {1997}
}
@article{DANIEL1997,
abstract = {This article develops and applies new measures of portfolio performance which use benchmarks based on the characteristics of stocks held by the portfolios that are evaluated. Specifically, the benchmarks are constructed from the returns of 125 passive portfolios that are matched with stocks held in the evaluated portfolio on the basis of the market capitalization, book-to-market, and prior-year return characteristics of those stocks. Based on these benchmarks, “Characteristic Timing” and “Characteristic Selectivity” measures are developed that detect, respectively, whether portfolio managers successfully time their portfolio weightings on these characteristics and whether managers can select stocks that outperform the average stock having the same characteristics. We apply these measures to a new database of mutual fund holdings covering over 2500 equity funds from 1975 to 1994. Our results show that mutual funds, particularly aggressive-growth funds, exhibit some selectivity ability, but that funds exhibit no characteristic timing ability.},
author = {DANIEL, KENT and GRINBLATT, MARK and TITMAN, SHERIDAN and WERMERS, RUSS},
doi = {10.1111/j.1540-6261.1997.tb02724.x},
isbn = {00221082},
issn = {00221082},
journal = {The Journal of Finance},
number = {3},
pages = {1035--1058},
title = {{Measuring Mutual Fund Performance with Characteristic-Based Benchmarks}},
url = {http://www.kentdaniel.net/papers/published/jf97{\_}2.pdf http://doi.wiley.com/10.1111/j.1540-6261.1997.tb02724.x},
volume = {52},
year = {1997}
}
@article{Daniel1997a,
abstract = {Firm sizes and book-to-market ratios are both highly correlated with the average returns of common stocks. Fama and French (1993) argue that the association between these characteristics and returns arise because the characteristics are proxies for nondiversifiable factor risk. In contrast, the evidence in this article indicates that the return premia on small capitalization and high book-to-market stocks does not arise because of the comovements of these stocks with pervasive factors. It is the characteristics rather than the covariance structure of returns that appear to explain the cross-sectional variation in stock returns.},
author = {Daniel, Kent and Titman, Sheridan},
doi = {10.2307/2329554},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daniel, Titman - 1997 - Evidence on the Characteristics of Cross Sectional Variation in Stock Returns.pdf:pdf},
isbn = {00221082},
issn = {00221082},
journal = {The Journal of Finance},
number = {1},
pages = {1},
pmid = {2329554},
title = {{Evidence on the Characteristics of Cross Sectional Variation in Stock Returns}},
url = {http://www.jstor.org/stable/2329554?origin=crossref},
volume = {52},
year = {1997}
}
@article{Cohen1996,
abstract = {We refine the description of the characteristics that best explain cross-sectional and common variation in expected stock returns. By breaking BE/ME into its inter-and intra-industry components, we find that the book-to-market effect is primarily intra-industry, in stark contrast to results for the momentum effect. We create factor-mimicking portfolios that imply an extremely high ex post price of risk, and appear to be more efficient than the simple book-to-market factor-mimicking portfolio of Fama and French (1993). We then use these intra-industry portfolios to test the characteristic-based asset-pricing model of Daniel and Titman (1997). Our results are inconsistent with that behavioral model.},
author = {Cohen, Randolph B and Polk, Christopher K},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen, Polk - Unknown - The Impact of Industry Factors in Asset-Pricing Tests.pdf:pdf},
journal = {Mimeo},
keywords = {CAPM-empirisch,diversificatie-sector},
number = {June 1994},
pages = {30+},
title = {{An investigation of the impact of industry factors in asset-pricing tests}},
volume = {02163},
year = {1996}
}
@book{Salus1994,
abstract = {UNIX is a software system that is simple, elegant, portable, and powerful. It grew in popularity without the benefit of a large marketing organization. Programmers kept using it; big companies kept fighting it. After a decade, it was clear that the users had won. A Quarter Century of UNIX is the first book to explain this incredible success, using the words of its creators, developers and users to illustrate how the sociology of a technical group can overwhelm the intent of multi-billion-dollar corporations. In preparing to write this book, Peter Salus interviewed over 100 of these key figures and gathered relevant information from Australia to Austria. This is the book that turns UNIX folklore into UNIX history. Features: provides the first documented history of the development of the UNIX operating system, includes interviews with over 100 key figures in the UNIX community, contains classic photos and illustrations, and explains why UNIX succeeded.},
author = {Salus, Peter H.},
isbn = {0201547775},
pages = {256},
publisher = {Addison-Wesley Pub. Co},
title = {{A quarter century of UNIX}},
url = {https://dl.acm.org/citation.cfm?id=191771{\&}preflayout=tabs},
year = {1994}
}
@misc{Fama1992,
abstract = {Two easily measured variables, size and book-to-market equity, combine to capture the cross-sectional variation in average stock returns associated with market beta, size, leverage, book-to-market equity, and earings-price ratios. Moreover, when the tests allow for variation in beta that is unrelated to size, the relation between market beta and average return is flat, even when beta is the only explanatory variable.},
archivePrefix = {arXiv},
arxivId = {1011.1669},
author = {Fama, E. and French, K.},
booktitle = {The Journal of Finance},
doi = {10.2307/2329112},
eprint = {1011.1669},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Fama-92.pdf:pdf},
isbn = {00221082},
issn = {1540-6261},
number = {2},
pages = {427--465},
pmid = {2329112},
title = {{The Cross-Section of Expected Stock Returns}},
volume = {47},
year = {1992}
}
@article{FAMA1992,
abstract = {ABSTRACT Two easily measured variables, size and book-to-market equity, combine to capture the cross-sectional variation in average stock returns associated with market {\$}\beta{\$}, size, leverage, book-to-market equity, and earnings-price ratios. Moreover, when the tests allow ... {\$}\backslash{\$}n},
archivePrefix = {arXiv},
arxivId = {1011.1669},
author = {FAMA, EUGENE F. and FRENCH, KENNETH R.},
doi = {10.1111/j.1540-6261.1992.tb04398.x},
eprint = {1011.1669},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/FAMA, FRENCH - 1992 - The Cross‐Section of Expected Stock Returns.pdf:pdf},
isbn = {1540-6261},
issn = {15406261},
journal = {The Journal of Finance},
month = {jun},
number = {2},
pages = {427--465},
pmid = {2329112},
publisher = {Blackwell Publishing Ltd},
title = {{The Cross‐Section of Expected Stock Returns}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.1992.tb04398.x},
volume = {47},
year = {1992}
}
@article{Lehmann1988,
abstract = {This paper uses maximum-likelihood factor analysis of large cross-sections to examine the validity of the arbitrage pricing theory (APT). We are unable to explain the expected returns on firm size portfolios, although we do explain the expected returns on portfolios formed on the basis of dividend yield and own variance, where risk adjustment using the usual CAPM market proxies fails. We also compare alternate versions of the APT and sharply reject the hypothesis that basis portfolios formed to mimic the factors span the mean-variance frontier of the individual assets.},
author = {Lehmann, Bruce N. and Modest, David M.},
doi = {10.1016/0304-405X(88)90061-X},
issn = {0304-405X},
journal = {Journal of Financial Economics},
month = {sep},
number = {2},
pages = {213--254},
publisher = {North-Holland},
title = {{The empirical foundations of the arbitrage pricing theory}},
url = {https://www.sciencedirect.com/science/article/pii/0304405X8890061X},
volume = {21},
year = {1988}
}
@misc{BLACK1986,
abstract = {The effects of noise on the world, and on our views of the world, are profound, Noise in the sense of a large number of small events is often a causal factor much more powerful than a small number of large events can be. Noise makes trading in financial markets possible, and thus allows us to observe prices for financial assets. Noise causes markets to be somewhat inefficient, but often prevents us from taking advantage of ineffiencies. Noise in the form of uncertainty about future tases and technology by sector causes business cycles, and makes them highly resistant to improvement through government intervention. Noise in in the form of expectations that need not follow rational rules causes inflation to be what it is, at least in the absense of a gold standard or fixed exchange rates. Noise in the form of uncertainty about what relative prices would be with other exchange rates makes us think incorrectly that changes in exchange rates or inflation rates cause changes in trade or investment flows or economic activity. Most generally, noise makes it very difficult to test either practical or academic theories about the way that financial or economic markets work. We are forced to act largely in the dark.},
author = {BLACK, FISCHER},
booktitle = {The Journal of Finance},
doi = {10.1111/j.1540-6261.1986.tb04513.x},
file = {:home/riaz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/BLACK - 1986 - Noise.pdf:pdf},
isbn = {1540-6261},
issn = {15406261},
number = {3},
pages = {529--543},
title = {{Noise}},
volume = {41},
year = {1986}
}
@article{Dewald1986,
abstract = {This paper examines the role of replication in empirical economic research. It presents the findings of a two-year study that collected programs and data from authors and attempted to replicate their published results. Our research provides new and important information about the extent and causes of failures to replicate published results in economics. Our findings suggest that inadvertent errors in published empirical articles are a commonplace rather thana rare occurrence. CR - Copyright {\&}{\#}169; 1986 American Economic Association},
author = {Dewald, William G and Thursby, Jerry G. and Anderson, Richard G.},
doi = {10.2307/1806061},
isbn = {0002-8282},
issn = {00028282},
journal = {The American Economic Review},
number = {4},
pages = {587--603},
publisher = {American Economic Association},
title = {{Replication in Empirical Economics: The Journal of Money, Credit and Banking Project}},
url = {https://econpapers.repec.org/article/aeaaecrev/v{\_}3a76{\_}3ay{\_}3a1986{\_}3ai{\_}3a4{\_}3ap{\_}3a587-603.htm http://www.jstor.org/stable/1806061},
volume = {76},
year = {1986}
}
@article{Lehmann1985,
abstract = {The Arbitrage Pricing Theory (APT) of Ross (1976) presumes that a factor model describes security returns. In this paper, we provide a comprehensive examination of the merits of various strategies for constructing basis portfolios that are, in principle, highly correlated with the common factors affecting security returns. Three main conclusions emerge from our study. First, increasing the number of securities included in the analysis dramatically improves basis portfolio performance. Our results indicate that factor models involving 750 securities provide markedly superior performance to those involving 30 or 250 securities. Second, comparatively efficient estimation procedures such as maximum likelihood and restricted maximum likelihood factor analysis(which imposes the APT mean restriction) significantly outperform the less efficient instrumental variables and principal components procedures that have been proposed in the literature. Third, a variant of the usual Fame-MacBeth portfolio formation procedure, which we call the minimum idiosyncratic risk portfolio formation procedure, outperformed the Fama-MacBeth procedure and proved equal toor better than more expensive quadratic programming procedures.},
address = {Cambridge, MA},
author = {Lehmann, Bruce N. and Modest, David M.},
doi = {10.3386/w1726},
institution = {National Bureau of Economic Research},
journal = {Business},
month = {oct},
title = {{The empirical Foundations of the Arbitrage The Arbitrage Pricing Theory II: the optimal construction of basis portfolios}},
url = {http://www.nber.org/papers/w1726.pdf},
year = {1985}
}
@article{Fama1973,
abstract = {This paper tests the relationship between average return and risk for New York Stock Exchange common stocks. The theoretical basis of the tests is the "two-parameter" portfolio model and models of market equilibrium derived from the two-parameter portfolio model. We cannot reject the hypothesis of these models that the pricing of common stocks reflects the attempts of risk-averse investors to hold portfolios that are "efficient" in terms of expected value and dispersion of return. Moreover, the observed "fair game" properties of the coefficients and residuals of the risk-return regressions are consistent with an "efficient capital market"--that is, a market where prices of securities},
author = {Fama, Eugene F. and MacBeth, James D.},
doi = {10.2307/1831028},
file = {:home/riaz/Downloads/Fama-Macbeth.pdf:pdf},
journal = {Journal of Political Economy},
pages = {607--636},
publisher = {The University of Chicago Press},
title = {{Risk, Return, and Equilibrium: Empirical Tests}},
url = {https://www.jstor.org/stable/1831028},
volume = {81},
year = {1973}
}
